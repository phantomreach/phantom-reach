{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNujRuBlfCc88HbfqEvF9rZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShovalBenjer/phantom-reach/blob/main/Image_detection_Model_Comparasion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model         | MPII PCKh (%) | COCO Keypoint AP (%) | Speed             | Strengths                                     |\n",
        "|---------------|---------------|-----------------------|-------------------|-----------------------------------------------|\n",
        "| Mediapipe     | ~70–80*       | ~60*                 | Excellent (Real-time) | Lightweight, deployable on edge devices.       |\n",
        "| ViTPose       | ~90+          | 78–82                | Moderate          | Transformer-based, high precision.            |\n",
        "| HigherHRNet   | ~91           | 75–80                | Moderate          | Excellent for detailed single-person poses.   |\n",
        "| Lite-HRNet    | ~85           | 65–70                | Good              | Efficient and lightweight for real-time.      |\n",
        "| PoseNet       | ~80           | ~60–65               | Good              | Simple, good for single-person tasks.         |\n"
      ],
      "metadata": {
        "id": "tVHei7eqWwq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dependencies**"
      ],
      "metadata": {
        "id": "1pHUzyFjIrvj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gPhsrGL4V4S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24948f87-4b9e-4541-b628-46e78a8abd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.16.0, 0.16.1, 0.21.5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.6.0 Requires-Python >=3.5,<3.9; 0.6.0.1 Requires-Python >=3.5,<3.9; 0.6.1 Requires-Python >=3.5,<3.9; 0.6.1.1 Requires-Python >=3.5,<3.9; 0.6.2 Requires-Python >=3.5,<3.9; 0.6.3 Requires-Python >=3.5,<3.9; 0.6.4 Requires-Python >=3.5,<3.9; 0.6.5 Requires-Python >=3.5,<3.9; 0.6.5.1 Requires-Python >=3.5,<3.9; 0.6.5.2 Requires-Python >=3.5,<3.9; 0.6.6 Requires-Python >=3.5,<3.9; 0.7.0 Requires-Python >=3.5,<3.9\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement fiftyone==0.18.1 (from versions: 0.1.0, 0.1.0.1, 0.1.2, 0.1.3, 0.2.0rc1, 0.2.0, 0.2.1, 0.3.0, 0.4.0, 0.4.1, 0.5.0, 0.5.1, 0.5.2, 0.5.2.1, 0.5.3, 0.5.3.1, 0.5.4, 0.5.5, 0.5.5.1, 0.5.6, 0.7.0.1, 0.7.1, 0.7.1.1, 0.7.1.2, 0.7.1.3, 0.7.1.4, 0.7.2, 0.7.3, 0.7.3.1, 0.7.3.2, 0.7.3.3, 0.7.3.4, 0.7.4, 0.8.0, 0.8.0.1, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.10.0, 0.11.0, 0.11.1, 0.11.2, 0.11.2.1, 0.12.0, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.14.2, 0.14.3, 0.14.4, 0.15.0, 0.15.0.1, 0.15.0.2, 0.15.1, 0.16.2, 0.16.3, 0.16.4, 0.16.5, 0.16.6, 0.17.0, 0.17.1, 0.17.2, 0.18.0rc0, 0.18.0, 0.18.1rc0, 0.18.1rc1, 0.18.1rc2, 0.18.1rc3, 0.18.1rc4, 0.18.1rc5, 0.18.1rc6, 0.18.1rc7, 0.18.1rc8, 0.18.1rc9, 0.18.1rc10, 0.18.1rc11, 0.18.1rc12, 0.18.1rc13, 0.18.1rc14, 0.18.1rc15, 0.18.1rc16, 0.18.1rc17, 0.18.1rc18, 0.18.1rc19, 0.18.1rc20, 0.18.1rc21, 0.18.1rc22, 0.18.1rc23, 0.18.1rc24, 0.18.1rc25, 0.18.1rc26, 0.19.0, 0.19.1rc0, 0.19.1rc1, 0.19.1, 0.20.0, 0.20.1rc1, 0.20.1rc2, 0.20.1rc3, 0.20.1, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.21.4, 0.21.6, 0.22.0, 0.22.1, 0.22.2, 0.22.3, 0.23.0rc1, 0.23.0rc2, 0.23.0, 0.23.1, 0.23.2, 0.23.3rc1, 0.23.3, 0.23.4, 0.23.5, 0.23.6, 0.23.7, 0.23.8, 0.24.0, 0.24.1, 0.25.0, 0.25.1, 0.25.2, 1.0.0, 1.0.1, 1.0.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for fiftyone==0.18.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting mediapipe==0.10.0\n",
            "  Downloading mediapipe-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.0) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.0) (24.3.25)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.0) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.0) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.0) (4.10.0.84)\n",
            "Collecting protobuf<4,>=3.11 (from mediapipe==0.10.0)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.0)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.0) (1.17.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.0) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.0) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.0) (1.16.0)\n",
            "Downloading mediapipe-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.0 protobuf-3.20.3 sounddevice-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4d8632e6c8124da3ab88e89f81d0a78d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.7.0.72\n",
            "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless==4.7.0.72) (1.26.4)\n",
            "Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.10.0.84\n",
            "    Uninstalling opencv-python-headless-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-headless-4.10.0.84\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "albumentations 1.4.20 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-python-headless-4.7.0.72\n",
            "Collecting matplotlib==3.7.1\n",
            "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.1) (1.16.0)\n",
            "Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.0\n",
            "    Uninstalling matplotlib-3.8.0:\n",
            "      Successfully uninstalled matplotlib-3.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "75fbfdbf88de46d5a2e5a43a1828ada4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.19 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "4a743a084d924ffbaa9b032ae7c1c606"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.14.1\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==0.13.1\n",
            "  Downloading torchaudio-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2024.8.30)\n",
            "Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-0.13.1-cp310-cp310-manylinux1_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m145.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -U pip\n",
        "!pip install fiftyone==0.18.1\n",
        "!pip install mediapipe==0.10.0\n",
        "!pip install opencv-python-headless==4.7.0.72\n",
        "!pip install matplotlib==3.7.1\n",
        "!pip install numpy==1.23.5\n",
        "!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1\n",
        "!pip install mmcv-full==1.7.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html\n",
        "!pip install mmdet==2.28.1\n",
        "!pip install mmpose==0.29.0\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "d68wC4T3I7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import fiftyone as fo\n",
        "import fiftyone.utils.huggingface as fouh\n",
        "import mediapipe as mp\n",
        "from mmpose.apis import init_pose_model, inference_top_down_pose_model\n",
        "from mmpose.datasets import DatasetInfo\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "from tqdm import tqdm\n",
        "import requests"
      ],
      "metadata": {
        "id": "o0ArPrgn4eIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and Preprocess the Dataset - Filtering relevant pictures**"
      ],
      "metadata": {
        "id": "4phPX9aMI_gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MPII Human Pose Dataset from FiftyOne\n",
        "dataset = fouh.load_from_hub(\"Voxel51/MPII_Human_Pose_Dataset\")\n",
        "print(f\"Total dataset size: {len(dataset)} samples.\")\n",
        "\n",
        "# Define the filter function\n",
        "def filter_single_person_facing_camera(sample):\n",
        "    # Check if there is exactly one person in the image\n",
        "    if sample.annopoints and len(sample.annopoints) == 1:\n",
        "        keypoints = sample.annopoints[0].keypoints\n",
        "        # Define indices for left and right shoulders (MPII keypoint indices)\n",
        "        left_shoulder = next((kp for kp in keypoints if kp.id == 13), None)\n",
        "        right_shoulder = next((kp for kp in keypoints if kp.id == 12), None)\n",
        "        if left_shoulder and right_shoulder:\n",
        "            # Calculate horizontal distance between shoulders\n",
        "            distance = abs(left_shoulder.x - right_shoulder.x)\n",
        "            # Determine if the person is facing the camera\n",
        "            is_facing_camera = distance < 50  # Adjust threshold as needed\n",
        "            return is_facing_camera\n",
        "    return False"
      ],
      "metadata": {
        "id": "eflJqoYBmJBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply filter\n",
        "filtered_view = dataset.filter_labels(\"annopoints\", filter_single_person_facing_camera)\n",
        "filtered_dataset = filtered_view.clone()  # Create a clone to work with\n",
        "print(f\"Filtered dataset size: {len(filtered_dataset)} samples.\")"
      ],
      "metadata": {
        "id": "eyc8EMXkmK6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export filtered dataset with keypoints annotations\n",
        "filtered_dir = \"filtered_mpii\"\n",
        "if not os.path.exists(filtered_dir):\n",
        "    filtered_dataset.export(\n",
        "        export_dir=filtered_dir,\n",
        "        dataset_type=fo.types.FiftyOneDataset,\n",
        "        label_field=\"annopoints\",  # Ensure keypoints are included\n",
        "    )\n",
        "print(\"Filtered dataset exported.\")"
      ],
      "metadata": {
        "id": "wV4nbM-SmNDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Classes and Evaluation Function**"
      ],
      "metadata": {
        "id": "cbn623MKJcvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, dest_path):\n",
        "    if not os.path.exists(dest_path):\n",
        "        print(f\"Downloading {url} to {dest_path}...\")\n",
        "        r = requests.get(url, allow_redirects=True)\n",
        "        open(dest_path, 'wb').write(r.content)\n",
        "        print(\"Download completed.\")\n",
        "    else:\n",
        "        print(f\"{dest_path} already exists.\")\n",
        "\n",
        "# MediaPipe Pose Model\n",
        "class MediaPipePoseModel:\n",
        "    def __init__(self):\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.pose = self.mp_pose.Pose(static_image_mode=True)\n",
        "\n",
        "    def predict(self, image):\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = self.pose.process(image_rgb)\n",
        "        if results.pose_landmarks:\n",
        "            keypoints = []\n",
        "            for lm in results.pose_landmarks.landmark:\n",
        "                x = lm.x * image.shape[1]\n",
        "                y = lm.y * image.shape[0]\n",
        "                visibility = lm.visibility\n",
        "                keypoints.append([x, y, visibility])\n",
        "            return np.array(keypoints)\n",
        "        return np.array([])\n",
        "\n",
        "# Lite-HRNet Model using MMPose\n",
        "class LiteHRNetModel:\n",
        "    def __init__(self):\n",
        "        # Download the config and checkpoint files\n",
        "        config_url = 'https://raw.githubusercontent.com/open-mmlab/mmpose/master/configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/litehrnet/coco/litehrnet_30_coco_256x192.py'\n",
        "        checkpoint_url = 'https://download.openmmlab.com/mmpose/top_down/litehrnet/litehrnet_30_coco_256x192-4bdb48f9_20210423.pth'\n",
        "        config_path = 'litehrnet_30_coco_256x192.py'\n",
        "        checkpoint_path = 'litehrnet_30_coco_256x192.pth'\n",
        "        download_file(config_url, config_path)\n",
        "        download_file(checkpoint_url, checkpoint_path)\n",
        "\n",
        "        # Initialize the pose model\n",
        "        self.model = init_pose_model(config_path, checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.dataset_info = self.model.cfg.data['test'].get('dataset_info', None)\n",
        "        if self.dataset_info is None:\n",
        "            raise ValueError(\"Dataset info is missing in the config file.\")\n",
        "        else:\n",
        "            self.dataset_info = DatasetInfo(self.dataset_info)\n",
        "\n",
        "        # Initialize a person detector (YOLOv5)\n",
        "        detector_config_url = 'https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/faster_rcnn/faster_rcnn_r50_fpn_coco.py'\n",
        "        detector_checkpoint_url = 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
        "        detector_config_path = 'faster_rcnn_r50_fpn_coco.py'\n",
        "        detector_checkpoint_path = 'faster_rcnn_r50_fpn_coco.pth'\n",
        "        download_file(detector_config_url, detector_config_path)\n",
        "        download_file(detector_checkpoint_url, detector_checkpoint_path)\n",
        "\n",
        "        self.detector = init_detector(detector_config_path, detector_checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Detect people in the image\n",
        "        mmdet_results = inference_detector(self.detector, image)\n",
        "        # Keep only person class (class_id = 0)\n",
        "        person_results = []\n",
        "        for bbox in mmdet_results[0]:\n",
        "            if bbox[4] >= 0.5:  # Confidence threshold\n",
        "                person_results.append({'bbox': bbox[:4]})\n",
        "\n",
        "        if not person_results:\n",
        "            return np.array([])\n",
        "\n",
        "        # Run pose estimation\n",
        "        pose_results, _ = inference_top_down_pose_model(\n",
        "            self.model,\n",
        "            image,\n",
        "            person_results,\n",
        "            bbox_thr=0.5,\n",
        "            format='xyxy',\n",
        "            dataset=self.model.cfg.data['test']['type'],\n",
        "            dataset_info=self.dataset_info,\n",
        "            return_heatmap=False,\n",
        "            outputs=None)\n",
        "\n",
        "        if pose_results:\n",
        "            # Assuming single person\n",
        "            keypoints = pose_results[0]['keypoints']\n",
        "            return keypoints\n",
        "        return np.array([])\n",
        "\n",
        "# ViTPose Model using MMPose\n",
        "class ViTPoseModel:\n",
        "    def __init__(self):\n",
        "        # Download the config and checkpoint files\n",
        "        config_url = 'https://raw.githubusercontent.com/ViTAE-Transformer/ViTPose/main/configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/vitpose_base_coco_256x192.py'\n",
        "        checkpoint_url = 'https://github.com/ViTAE-Transformer/ViTPose/releases/download/v0.0.1/vitpose-b-multi-coco.pth'\n",
        "        config_path = 'vitpose_base_coco_256x192.py'\n",
        "        checkpoint_path = 'vitpose_base_coco.pth'\n",
        "        download_file(config_url, config_path)\n",
        "        download_file(checkpoint_url, checkpoint_path)\n",
        "\n",
        "        # Initialize the pose model\n",
        "        self.model = init_pose_model(config_path, checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.dataset_info = self.model.cfg.data['test'].get('dataset_info', None)\n",
        "        if self.dataset_info is None:\n",
        "            raise ValueError(\"Dataset info is missing in the config file.\")\n",
        "        else:\n",
        "            self.dataset_info = DatasetInfo(self.dataset_info)\n",
        "\n",
        "        # Initialize a person detector\n",
        "        detector_config_url = 'https://raw.githubusercontent.com/open-mmlab/mmdetection/master/configs/faster_rcnn/faster_rcnn_r50_fpn_coco.py'\n",
        "        detector_checkpoint_url = 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
        "        detector_config_path = 'faster_rcnn_r50_fpn_coco.py'\n",
        "        detector_checkpoint_path = 'faster_rcnn_r50_fpn_coco.pth'\n",
        "        download_file(detector_config_url, detector_config_path)\n",
        "        download_file(detector_checkpoint_url, detector_checkpoint_path)\n",
        "\n",
        "        self.detector = init_detector(detector_config_path, detector_checkpoint_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Detect people in the image\n",
        "        mmdet_results = inference_detector(self.detector, image)\n",
        "        # Keep only person class (class_id = 0)\n",
        "        person_results = []\n",
        "        for bbox in mmdet_results[0]:\n",
        "            if bbox[4] >= 0.5:  # Confidence threshold\n",
        "                person_results.append({'bbox': bbox[:4]})\n",
        "\n",
        "        if not person_results:\n",
        "            return np.array([])\n",
        "\n",
        "        # Run pose estimation\n",
        "        pose_results, _ = inference_top_down_pose_model(\n",
        "            self.model,\n",
        "            image,\n",
        "            person_results,\n",
        "            bbox_thr=0.5,\n",
        "            format='xyxy',\n",
        "            dataset=self.model.cfg.data['test']['type'],\n",
        "            dataset_info=self.dataset_info,\n",
        "            return_heatmap=False,\n",
        "            outputs=None)\n",
        "\n",
        "        if pose_results:\n",
        "            # Assuming single person\n",
        "            keypoints = pose_results[0]['keypoints']\n",
        "            return keypoints\n",
        "        return np.array([])\n",
        "\n",
        "def compute_head_size(gt_keypoints):\n",
        "    \"\"\"\n",
        "    Computes the head size based on the distance between head top and upper neck.\n",
        "    \"\"\"\n",
        "    head_top = next((kp for kp in gt_keypoints if kp[2] == 9), None)\n",
        "    upper_neck = next((kp for kp in gt_keypoints if kp[2] == 8), None)\n",
        "    if head_top is not None and upper_neck is not None:\n",
        "        head_size = np.linalg.norm([head_top[0] - upper_neck[0], head_top[1] - upper_neck[1]])\n",
        "    else:\n",
        "        head_size = 1.0  # Default value if head keypoints are missing\n",
        "    return head_size\n",
        "\n",
        "def pckh(predictions, ground_truths, head_sizes):\n",
        "    \"\"\"\n",
        "    Computes the Percentage of Correct Keypoints normalized by head size (PCKh).\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for pred, gt, head_size in zip(predictions, ground_truths, head_sizes):\n",
        "        if pred.shape[0] == 0 or gt.shape[0] == 0:\n",
        "            continue\n",
        "        # Align keypoints by id\n",
        "        pred_dict = {i: kp for i, kp in enumerate(pred)}\n",
        "        gt_dict = {int(kp[2]): kp[:2] for kp in gt}\n",
        "        matched_ids = set(pred_dict.keys()).intersection(set(gt_dict.keys()))\n",
        "        distances = []\n",
        "        for idx in matched_ids:\n",
        "            pred_kp = pred_dict[idx][:2]\n",
        "            gt_kp = gt_dict[idx]\n",
        "            distance = np.linalg.norm(pred_kp - gt_kp) / head_size\n",
        "            distances.append(distance)\n",
        "            if distance < 0.5:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "def evaluate_model(model, dataset_dir):\n",
        "    predictions, ground_truths, inference_times, head_sizes = [], [], [], []\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = fo.Dataset.from_dir(\n",
        "        dataset_dir=dataset_dir,\n",
        "        dataset_type=fo.types.FiftyOneDataset,\n",
        "    )\n",
        "\n",
        "    for sample in tqdm(dataset):\n",
        "        image_path = sample.filepath\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Access ground truth keypoints\n",
        "        gt_annopoints = sample.annopoints[0]\n",
        "        gt_keypoints = []\n",
        "        for kp in gt_annopoints.keypoints:\n",
        "            gt_keypoints.append([kp.x, kp.y, kp.id])\n",
        "        gt_keypoints = np.array(gt_keypoints)\n",
        "\n",
        "        # Compute head size (distance between head top and upper neck)\n",
        "        head_size = compute_head_size(gt_keypoints)\n",
        "\n",
        "        start_time = time.time()\n",
        "        pred_keypoints = model.predict(image)\n",
        "        end_time = time.time()\n",
        "\n",
        "        predictions.append(pred_keypoints)\n",
        "        ground_truths.append(gt_keypoints)\n",
        "        head_sizes.append(head_size)\n",
        "        inference_times.append(end_time - start_time)\n",
        "\n",
        "    avg_time = np.mean(inference_times)\n",
        "    fps = 1 / avg_time if avg_time > 0 else float(\"inf\")\n",
        "    accuracy = pckh(predictions, ground_truths, head_sizes)\n",
        "\n",
        "    return {\"PCKh\": accuracy, \"FPS\": fps}\n"
      ],
      "metadata": {
        "id": "jX-rxc9qJIeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    dataset_dir = \"filtered_mpii\"\n",
        "\n",
        "    # Initialize models\n",
        "    print(\"Initializing MediaPipePoseModel...\")\n",
        "    mediapipe_model = MediaPipePoseModel()\n",
        "\n",
        "    print(\"Initializing LiteHRNetModel...\")\n",
        "    lite_hrnet_model = LiteHRNetModel()\n",
        "\n",
        "    print(\"Initializing ViTPoseModel...\")\n",
        "    vitpose_model = ViTPoseModel()\n",
        "\n",
        "    # Evaluate each model\n",
        "    print(\"Evaluating MediaPipe...\")\n",
        "    mediapipe_metrics = evaluate_model(mediapipe_model, dataset_dir)\n",
        "    print(\"MediaPipe Metrics:\", mediapipe_metrics)\n",
        "\n",
        "    print(\"Evaluating Lite-HRNet...\")\n",
        "    lite_hrnet_metrics = evaluate_model(lite_hrnet_model, dataset_dir)\n",
        "    print(\"Lite-HRNet Metrics:\", lite_hrnet_metrics)\n",
        "\n",
        "    print(\"Evaluating ViTPose...\")\n",
        "    vitpose_metrics = evaluate_model(vitpose_model, dataset_dir)\n",
        "    print(\"ViTPose Metrics:\", vitpose_metrics)\n"
      ],
      "metadata": {
        "id": "B3oibFShmqZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load preprocessed dataset directory\n",
        "    dataset_dir = \"filtered_mpii\"\n",
        "\n",
        "    # Initialize models\n",
        "    mediapipe_model = MediaPipePoseModel()\n",
        "    yolov8_model = YOLOv8PoseModel()\n",
        "\n",
        "    # Evaluate models\n",
        "    print(\"Evaluating MediaPipe Pose...\")\n",
        "    mediapipe_metrics = evaluate_model(mediapipe_model, dataset_dir)\n",
        "    print(\"MediaPipe Metrics:\", mediapipe_metrics)\n",
        "\n",
        "    print(\"Evaluating YOLOv8 Pose...\")\n",
        "    yolov8_metrics = evaluate_model(yolov8_model, dataset_dir)\n",
        "    print(\"YOLOv8 Metrics:\", yolov8_metrics)\n",
        "\n",
        "    # Visualization example\n",
        "    def visualize_sample(image_path, keypoints):\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(image)\n",
        "        for kp in keypoints:\n",
        "            plt.scatter(kp[0] * image.shape[1], kp[1] * image.shape[0], color=\"red\")\n",
        "        plt.show()\n",
        "\n",
        "    # Example visualization\n",
        "    sample_image = \"filtered_mpii/some_image.jpg\"\n",
        "    keypoints = mediapipe_model.predict(cv2.imread(sample_image))\n",
        "    visualize_sample(sample_image, keypoints)\n"
      ],
      "metadata": {
        "id": "M2C-Y_ykJbTB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}