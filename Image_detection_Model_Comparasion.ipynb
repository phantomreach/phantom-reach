{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHcznsMMhpbX3bsGRxRgt+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShovalBenjer/phantom-reach/blob/main/Image_detection_Model_Comparasion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2gPhsrGL4V4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ba1ec8-d2d8-4bea-ac20-8ac3e8315926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision mediapipe opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "o0ArPrgn4eIo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_landmarks_to_json(landmarks, filepath):\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(landmarks, f)\n",
        "\n",
        "def load_human36m_and_mpii_dataset(human36m_path, mpii_path):\n",
        "    human36m_data = load_human36m_dataset(human36m_path)\n",
        "    mpii_data = load_mpii_dataset(mpii_path)  # Add MPII parsing here\n",
        "    return {\"Human3.6M\": human36m_data, \"MPII\": mpii_data}\n",
        "\n",
        "class PoseModelEvaluator:\n",
        "    def __init__(self, models, datasets):\n",
        "        self.models = models  # Dictionary of models {\"ModelName\": ModelInstance}\n",
        "        self.datasets = datasets  # Dictionary of datasets {\"DatasetName\": Dataset}\n",
        "\n",
        "    def evaluate(self):\n",
        "        all_results = {}\n",
        "        for dataset_name, dataset in self.datasets.items():\n",
        "            results = {}\n",
        "            for model_name, model in self.models.items():\n",
        "                preds, gts, inference_times = [], [], []\n",
        "\n",
        "                for image, gt in preprocess_data(dataset):\n",
        "                    start_time = time.time()\n",
        "                    pred = model.predict(image)\n",
        "                    end_time = time.time()\n",
        "                    preds.append(pred)\n",
        "                    gts.append(gt)\n",
        "                    inference_times.append(end_time - start_time)\n",
        "\n",
        "                # Metrics\n",
        "                pck = evaluate_pck(preds, gts)\n",
        "                mpjpe = evaluate_mpjpe(preds, gts)\n",
        "                avg_time = np.mean(inference_times)\n",
        "                fps = 1 / avg_time if avg_time > 0 else float('inf')\n",
        "\n",
        "                results[model_name] = {\n",
        "                    \"PCK\": pck,\n",
        "                    \"MPJPE\": mpjpe,\n",
        "                    \"Avg Inference Time\": avg_time,\n",
        "                    \"FPS\": fps,\n",
        "                }\n",
        "            all_results[dataset_name] = results\n",
        "        return all_results\n",
        "\n",
        "class MediaPipePoseModel:\n",
        "    def __init__(self):\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.pose = self.mp_pose.Pose()\n",
        "\n",
        "    def predict(self, image):\n",
        "        results = self.pose.process(image)\n",
        "        if results.pose_landmarks:\n",
        "            return [(lm.x, lm.y, lm.z) for lm in results.pose_landmarks.landmark]\n",
        "        else:\n",
        "            return []"
      ],
      "metadata": {
        "id": "D_EIEY2o4mcY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Instantiate models\n",
        "    models = {\n",
        "        \"OpenPose\": OpenPoseModel(),\n",
        "        \"PoseNet\": PoseNetModel(),\n",
        "        \"HRNet\": HRNetModel(),\n",
        "        \"MediaPipe Pose\": MediaPipePoseModel(),\n",
        "        \"YOLOv8\": YOLOv8PoseModel()\n",
        "    }\n",
        "\n",
        "    # Path to Human3.6M dataset\n",
        "    dataset_path = \"/path/to/human36m/dataset\"\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = PoseModelEvaluator(models, dataset_path)\n",
        "\n",
        "    # Evaluate and print results\n",
        "    results = evaluator.evaluate()\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"Results for {model_name}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value}\")\n"
      ],
      "metadata": {
        "id": "YYr70Eug7lbI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ee88f59b-a087-423e-9f86-85e767892799"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'OpenPoseModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dbac0b687c4b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Instantiate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     models = {\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m\"OpenPose\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOpenPoseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"PoseNet\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPoseNetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m\"HRNet\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHRNetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OpenPoseModel' is not defined"
          ]
        }
      ]
    }
  ]
}